{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pm2PquWSdsBU"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries \n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import argparse\n",
        "import os \n",
        "import re\n",
        "import pandas as pd \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoEijkASidpn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Starting a sparksession \n",
        "spark = SparkSession.builder\\\n",
        "                    .master(\"local\")\\\n",
        "                    .appName('Firstprogram')\\\n",
        "                    .getOrCreate()\n",
        "sc=spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "8OLpILgLlnvc"
      },
      "outputs": [],
      "source": [
        "# Read the input file and Calculating words count\n",
        "load_file = \"biographies.txt\"\n",
        "writeFile = open('updated_.txt', 'w')\n",
        "# Filterting the lines which starts with 'BG:'\n",
        "with open('biographies.txt', encoding = \"ISO-8859-1\") as f:\n",
        "  for line in f:\n",
        "    try:\n",
        "      if not (line.startswith('BG:')): \n",
        "        line = re.sub('[^A-Za-z0-9]+', ' ', line)\n",
        "        line = re.sub(r'[0-9]', ' ', line)\n",
        "        print(line) \n",
        "        # break\n",
        "\n",
        "        writeFile.write(line) # Saving the filtered lines in a seperate file as updateFile.txt\n",
        "    except UnicodeDecodeError:\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "d-iIPOxXwMyb"
      },
      "outputs": [],
      "source": [
        "#Loading the data file\n",
        "text_file = sc.textFile('updated_.txt')\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "                            .map(lambda word: (word, 1)) \\\n",
        "                           .reduceByKey(lambda x, y: x + y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "qqTzdUK_luBZ"
      },
      "outputs": [],
      "source": [
        "output = counts.collect()\n",
        "\n",
        "data_df = list()\n",
        "for (word, count) in output:\n",
        "  data_df.append((word, count))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnew3nmpmrBY",
        "outputId": "92525bf6-2e81-4c4e-e107-d8fb888f3ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             word    count\n",
            "0                  5127742\n",
            "1             NM:   664805\n",
            "2               *  2005591\n",
            "3             (17     2219\n",
            "4        official     1297\n",
            "...           ...      ...\n",
            "1727152     Tozlu        1\n",
            "1727153    Aybüke        1\n",
            "1727154    Üstel,        1\n",
            "1727155      Poj,        1\n",
            "1727156   Bankasi        1\n",
            "\n",
            "[1727157 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(data_df, columns=['word', 'count'])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9S50DDaED5gF"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"word_count.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "moS-eaVMoEnw"
      },
      "outputs": [],
      "source": [
        "# Stopping Spark-Session and Spark context\n",
        "sc.stop()\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
